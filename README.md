# Google Analytics Customer Revenue Prediction

### Business Problem:
 As for every business, the number of customer that generate revenue will be far less than the total customers that the business interacts with. So for every business its really important to understand, analyse and predict the areas of its revenue generation.
 
##### Kaggle Challenge Description:
visit: [Google Analytics Customer Revenue Prediction](https://www.kaggle.com/c/ga-customer-revenue-prediction/overview "Google Analytics Customer Revenue Prediction")
The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.

RStudio, the developer of free and open tools for R and enterprise-ready products for teams to scale and share work, has partnered with Google Cloud and Kaggle to demonstrate the business impact that thorough data analysis can have.

In this competition, you’re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data.

#### Source Of Data & Methodology:


##### Machine Learning Methodology:
In this challenge, we are tasked to predict the revenue generated by each over the period of _**December 1st 2018**_ to _**January 31st 2019**_ by using the historical data from _August 1st 2016_ to _October 15th 2018_. Please note that for hte time period that we are predicting we don't have any data.

##### Data:
We have been provided with `train_v2.csv` and `test_v.csv`. 
`train_v2.csv` - the updated training set - contains user transactions from _August 1st 2016_ to _April 30th 2018_.
`test_v2.csv` - the updated test set - contains user transactions from _May 1st 2018_ to _October 15th 2018_.

##### Objective:
`sample_submission_v2.csv` - a updated sample submission file in the correct format. Contains all fullVisitorIds in test_v2.csv. We have to Predicted LogRevenue column should make forward-looking predictions for each of these **_fullVisitorIds_** for the timeframe of **December 1st 2018** to **January 31st 2019**
##### File Descriptions and Features Provided:

Each .csv files has the data for the transactions for number of store vistis
**fullVisitorId** - A unique identifier for each user of the Google Merchandise Store. Our final submission will be dependent on this and will be used for aggregation.

**channelGrouping** - The channel via which the user came to the Store.

**date** - The date on which the user visited the Store.

**device** - The specifications for the device used to access the Store.(_json column_)

**geoNetwork** - This section contains information about the geography of the user.(_json column_)

**socialEngagementType** - Engagement type, either "Socially Engaged" or "Not Socially Engaged".

**totals** - This section contains aggregate values across the session.(_json column_)

**trafficSource** - This section contains information about the Traffic Source from which the session originated.(_json column_)

**visitId** - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.

**visitNumber** - The session number for this user. If this is the first session, then this is set to 1.

**visitStartTime** - The timestamp (expressed as POSIX time).

**hits** - This row and nested fields are populated for any and all types of hits. Provides a record of all page visits.

**customDimensions** - This section contains any user-level or session-level custom dimensions that are set for a session. This is a repeated field and has an entry for each dimension that is set.(_json column_)

_json column_: As we can see, there are few columns that are compressed in json format, we will normalize and convert it to normal feature.

##### Evaluation Metric and Target Variable:
![metric_1](https://i.ibb.co/nrdSBNX/metric-1.png)

For each user we have to find out the aggreagate of all transactions during the test data period and it will be log of the value.

##### Why use log on target variable?
We are asked to use log on the target variable:
![](https://i.ibb.co/4jyvsjn/Bar-Plots-Rev-Non-rev.png)
As we can see from this plot, the data is very highly skewwed. Very small number of customers are actually generating any revenue. Only 1.2193% of the customers are generating any revenue. So we are tasked to use log on the target variable.
[Source](http://onlinestatbook.com/2/transformations/log.html#:~:text=The%20log%20transformation%20can%20be,the%20assumptions%20of%20inferential%20statistics. "LogT ransformations")

Lets look at all the features we get after flatening all the json columns.
![](https://i.ibb.co/FYh7q0q/info.png)

#### Exploratory Data Analysis & Data Pre-processing:
**totals.transactionRevenue** is out target variable. We have 1,708,337 data points in train data. 
Lets look at the univarient plots for target variable
![](https://i.ibb.co/LngbfHZ/target-univariant.png "target variable PDF")

The plot on the right, the PDF of actual target_variable. The plot on the left is the PDF of log(target_variable).

Observations:
The PDF of totals.transactionRevenue, is almost normal, with mean at 17.5.

##### channelGrouping
![](https://i.ibb.co/WGvVqYM/channel-group.png)

This is the bar plots of **channelGrouping** indicating the counts on y_axis.
We can see that there are resonable number of unique categories in this features.

##### device.browsers
But some of the features contains like about 100+ unique categories. For Ex: device.browsers
![](https://i.ibb.co/2Pqtmsm/device-browser.png)

As we can see there are alot of categories. For this feature we have 129 categories. As we can see in the plot. Only few of the categories are repeating resonable times rest of them are like outliers. Most of them are repeating less than ten times. So we can understand that the categories that are repeating few times are not the reason for generating revenue. 

Since all non revenue generating data points are considered as zero, our model is only expected to predict greater than equal to **0**. 
Let's look at the percent of customers per browser.
![](https://i.ibb.co/MSmYsBD/device-browser-use.png)

As we can see after, Opera its been used by very customers. Hence we only keep the most popular browsers.

```python
popular_browsers = ['Chrome','Safari','Firefox','Internet Explorer','Android Webview','Edge','Samsung Internet','Opera Mini','Safari (in-app)','Opera']
train_df['device.browser'] = train_df['device.browser'].apply(lambda x: x if x in popular_browsers else 'unpopular_browser')
```
With this code we are limiting the number of categories in this feature.
After preprocessing we will be getting the below bar plot of browser counts.
![](https://i.ibb.co/Vgdckrt/device-browser-after-grouping-few-categories.png)
Now we can see that the number of unique browsers has reduced significantly.

Please note that the goal of doing this preprocessing is not to use one hot encoding, but to remove the outliers during the data preprocessing phase. This is only to reduce the cardinality of some of the features.

This will be particullarly helpfull when we have many unique categories. There are few features for which the unique categories are more than 500 categories. In that case we can limit the number of categoeis by looking at the distribution of the category value counts.

##### geoNetwork.city

This feture contains the name of the source city. We have the same problem as above. Like there are about 950+ unique cities. So it would not be possible to manually select few cities from our intuition.

Let's look at the PDF of the value counts all the cities.
![](https://i.ibb.co/XCq9GYx/device-city-pdf.png)

**Observation**:
As we can observe from the percentile plot on the left, there are many cities that are repeating with very less frequency compared to the cities from 90th to 100th percentile. The plot on the right is same plot but only between 0th and 90th percentile.

As we can see from these plots, only after 80th percentile that the cities are repeating for more than 250, we will be grouping all of the cities with lesser frequency into a single category. By performing this we dont loose much information because 250 is just a fraction of the size in our total train data.

**Code**:
```python
pre_processed_cities = []
for city_name,city_count in zip(train_df['geoNetwork.city'].value_counts().index,train_df['geoNetwork.city'].value_counts()):
  if ((city_count<(np.percentile(city_percentiles_values,80)) and (max(train_df['totals.transactionRevenue'][train_df['geoNetwork.city']==city_name])<1))):
    pass
  else:
    pre_processed_cities.append(city_name)

train_df['geoNetwork.city'] = train_df['geoNetwork.city'].apply(lambda x: x if x in pre_processed_cities else 'unknown_city')
```
After perfroming this pre-processing we still get about 185 unique cities.

There are few features which has similar problem. We have performed same pre-processing methodology as above.
**Columns with many category** - geoNetwork.country, geoNetwork.city,geoNetwork.city

**totals.hits**
totals.hits shows the number of times a store (or) product page URL has been access before making a transantion.

![](https://i.ibb.co/m6bvMcR/total-hits.png)
Observation:
* Most of the transactions are happening below hits = 150.
* As we can see there few outliers in the data but since the percentage of outliers very less we will continue to keep the data as is.

**trafficSource.source**:
This feature will hold the value of the source, i.e like the website from where its been redirected from. But the problem is we have categories which mean the same source name but the wording is not the same.Please see the example below.
![](https://i.ibb.co/cDcCX2p/source-words.png)
As highlighted above google, sites.google.com and group.google.com are all from the same parent website but its been termed as different. So we are going to group all them into 'google'. And same kind of grouping has been done for the major websites.

```python
def standardize_traffic_source(val):
    if 'google' in val:
        return 'google'
    elif 'youtube' in val:
        return 'youtube'
    elif 'facebook' in val:
        return 'facebook'
    elif 'yahoo' in val:
        return 'yahoo'
    elif 'baidu' in val:
        return 'baidu'
    elif 'aol' in val:
        return 'aol'
    elif 'quora' in val:
        return 'quora'
    elif 'reddit' in val:
        return 'reddit'
    elif 'pinterest' in val:
        return 'pinterest'
    elif 'bing' in val:
        return 'bing'
    elif 'wow' in val:
        return 'wow'
    elif 'blackboard' in val:
        return 'blackboard'
    elif len(val)>20:
        return 'Other'
    else:
        return val
```

With this script, we group all the source websites into single group based on the parent website.

**Year**:
![](https://i.ibb.co/jkPHD6t/year.png)
**Observations**:
The revenue generated has been fairly consistent over the years. But please do note that the data for 2018 is only available untill April 2018.

**Month**:
![](https://i.ibb.co/DpVG3V3/month.png)
**Observation**:
* We can see from this plot that there is a pattern in the way revenue has been distributed over the months.
* The revenue peaks out in June and August, and generally we can expect more sales during Summer sales.
* We can also note that the sales reduces drasatically during fall season suggesting that the products in the store are not catered towards fall holiday season.

**Days**:
![](https://i.ibb.co/7pWRZdT/day.png)
* This is a plot of date vs. transaction.revenue.
* The sales are mostly evenly split over all the days, except for the first part of first week.

##### **Training Methodology**:

All the features that have some categorical data will go through some of the data preprocessing techniques as above. Now lets understand the provided data for building a model. We were provided with Data from ```August 2016``` to ```October 2018```, as a whole when including train and test data but we are predicting for ```December 2018``` to ```January 2019```. This means that for those submission periods we don't have the data. So even though we have the test data the target variable is in future, so the transaction.revenue that is provided for test data is for that period.

Since we are predicting for future we have to we train the model several time by fixing a particular training window for ```X``` and future training window for our ***response variable***(```totals.transactionRevenue```).

##### **Window Aggregation**:

The table will show all the train and repose windows. So the training phase will be done for each period but the test will remain same for all the training phases.  

| train_time_from | train_time_end | response_window_from | response_window_end |
| :---: | :---: | :---: | :---: |
| 2016-08-24 | 2017-02-01 | 2017-04-01 | 2017-06-01 |
| 2016-10-24   | 2017-06-01 | 2017-08-01 | 2017-10-01 |
| 2016-12-24  | 2017-08-01 | 2017-10-01 | 2017-12-01 |
| 2017-02-23 | 2017-10-01 | 2017-12-01 | 2018-02-01 |
| 2017-04-25 | 2017-12-01 | 2018-02-01 | 2018-04-01 |
| 2017-06-26 | 2018-02-01 |2018-04-01 | 2018-06-01 |
| 2017-08-24 | 2018-04-01 |2018-06-01 | 2018-08-01 |
| 2017-10-24 | 2018-06-01 |2018-08-01 |2018-10-01 |
| 2017-12-24 | 2018-08-01 |2018-10-01 |2018-12-01 |
| 2018-02-23 | 2018-10-01 |2018-12-01 |2019-01-01 |

##### **Why are we doing this?**

The objective is to predict the total transaction.revenue for each customer not the revenue of each session or visitID.  
  
We split the data based on time because, if a person buy something in 2016 and is also a resular vistor over the years. The probability that he is going to spend higher amount in 2019 would be much lesser than a person who first visited the store in 2018.  

That is the reason we train the model accross various time frames and predict the revenue on test data at each time frame. 

We will average all of the observations at the end for our final prediction.


##### **Model Selection**:

We will try three advanced ML models first and then try to stack it.

**XGBOOST**:

